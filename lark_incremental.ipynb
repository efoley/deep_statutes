{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c2a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import pymupdf\n",
    "from lark import Lark, Tree, UnexpectedInput\n",
    "\n",
    "from deep_statutes.pdf.token_stream import pdf_to_token_stream, PDFTokenConversionOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35153092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these need to be inferred for the particular document\n",
    "LeftMargin = 72.\n",
    "IndentSize = 36."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bd07905",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/eric/Development/statutes_data/wy/raw_pdf/title03.pdf\"\n",
    "\n",
    "doc = pymupdf.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f0e2d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = PDFTokenConversionOptions(\n",
    "    left_margin=LeftMargin,\n",
    "    indent_size=IndentSize,\n",
    "    infer_centered=False,\n",
    "    font_sizes=[float('inf'), 12, float('inf'), float('inf')],\n",
    ")\n",
    "\n",
    "pdf_tokens_gen = pdf_to_token_stream(doc, options)\n",
    "text_buffer = io.StringIO()\n",
    "text_idx_to_pos = []\n",
    "for pos, pdf_token in pdf_tokens_gen:\n",
    "    text_buffer.write(\"\\n\")\n",
    "    text_idx_to_pos.append((text_buffer.tell(), pos))\n",
    "    text_buffer.write(pdf_token)\n",
    "\n",
    "text = text_buffer.getvalue()\n",
    "\n",
    "with open('foo.txt', 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f0e942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r'''\n",
    "_start: LINE* title\n",
    "_heading_start: title_start | chapter_start | article_start | section_start\n",
    "\n",
    "title: title_start _blank_line chapter+\n",
    "\n",
    "chapter: chapter_start _blank_line article+\n",
    "\n",
    "article: article_start _blank_line many_sections \n",
    "\n",
    "_centeredish: INDENT*\n",
    "\n",
    "title_start.2: LINE* _centeredish SPAN_M \"TITLE \" NAT \" - \" RAW_UPPER_TEXT _cont_upper_line?\n",
    "chapter_start.2: LINE* _centeredish SPAN_M \"CHAPTER \" NAT \" - \" RAW_UPPER_TEXT _cont_upper_line?\n",
    "article_start.2: LINE* _centeredish SPAN_M \"ARTICLE \" NAT \" - \" RAW_UPPER_TEXT _cont_upper_line?\n",
    "_cont_upper_line: LINE _centeredish _span_m_upper\n",
    "\n",
    "section_number: NAT \"-\" NAT \"-\" NAT\n",
    "section_start: INDENT SPAN_M_B section_number \".\" RAW_TEXT (LINE _sep{_span_m_b, LINE})? \n",
    "section: section_start (_blank_line _sep{paragraph, _blank_line})?\n",
    "\n",
    "many_sections: _sep{section, _blank_line}\n",
    "\n",
    "_blank_line: LINE LINE\n",
    "\n",
    "paragraph: INDENT* _sep{_multi_span_m, LINE}\n",
    "\n",
    "_span_m: SPAN_M RAW_TEXT\n",
    "_span_m_upper: SPAN_M RAW_UPPER_TEXT\n",
    "_span_m_b: SPAN_M_B RAW_TEXT\n",
    "\n",
    "_multi_span_m: _span_m+\n",
    "_multi_span_m_b: _span_m_b+\n",
    "\n",
    "NAT: /[1-9][0-9]*/\n",
    "\n",
    "RAW_TEXT: /(?:(?!<<)[^\\n])+/\n",
    "RAW_UPPER_TEXT: /(?:(?!<<)[^\\na-z])+/\n",
    "\n",
    "_sep{x, sep}: x (sep x)*\n",
    "\n",
    "//CENTER.2: /<<CENTER>>/\n",
    "INDENT.2: /<<INDENT>>/\n",
    "LINE.2: /<<LINE>>/\n",
    "BLOCK.2: /<<BLOCK>>/\n",
    "PAGE.2: /<<PAGE>>/\n",
    "\n",
    "SPAN_M.2: /<<SPAN_M>>/\n",
    "SPAN_M_B.2: /<<SPAN_M_B>>/\n",
    "\n",
    "EOL: /\\n/\n",
    "\n",
    "%ignore EOL\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d939af",
   "metadata": {},
   "outputs": [],
   "source": [
    "lark = Lark(grammar, parser='lalr', start='_heading_start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79ef0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "END_ACTION = '$END'\n",
    "\n",
    "def find_matches(text: str, start: str,lark: Lark) -> list[Tree]:\n",
    "    matched_parse_trees = []\n",
    "    if not lark.options.parser == 'lalr':\n",
    "        raise ValueError(\"Only lalr parser is supported\")\n",
    "    \n",
    "    pi = lark.parse_interactive(text, start=start)\n",
    "    lex_stream = pi.lexer_thread.lex(pi.parser_state)\n",
    "    while True:\n",
    "        # check if we are in the valid end state for a rule\n",
    "        choices = pi.choices()\n",
    "        if END_ACTION in choices:\n",
    "            #valid_parses.append(choices[END_ACTION])\n",
    "            # we feed the parser EOF to trick it into giving us back the parse tree for\n",
    "            # this range of the input text\n",
    "            r = pi.copy().feed_eof()\n",
    "            matched_parse_trees.append(r)\n",
    "        try:\n",
    "            token = next(lex_stream)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        except UnexpectedInput as e:\n",
    "            break\n",
    "        pi.feed_token(token)\n",
    "\n",
    "    return matched_parse_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1adc3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_parses = []\n",
    "\n",
    "for idx in range(len(text)):\n",
    "    valid_parses = find_matches(text[idx:], '_heading_start', lark)\n",
    "    idx_parses += [(idx, p) for p in valid_parses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adfa05e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 Tree(Token('RULE', '_heading_start'), [Tree(Token('RULE', 'title_start'), [Token('LINE', '<<LINE>>'), Token('INDENT', '<<INDENT>>'), Token('INDENT', '<<INDENT>>'), Token('INDENT', '<<INDENT>>'), Token('INDENT', '<<INDENT>>'), Token('SPAN_M', '<<SPAN_M>>'), Token('NAT', '3'), Token('RAW_UPPER_TEXT', 'GUARDIAN AND WARD ')])])\n",
      "54564 Tree(Token('RULE', '_heading_start'), [Tree(Token('RULE', 'chapter_start'), [Token('SPAN_M', '<<SPAN_M>>'), Token('NAT', '3'), Token('RAW_UPPER_TEXT', 'CONSERVATORSHIPS ')])])\n",
      "96686 Tree(Token('RULE', '_heading_start'), [Tree(Token('RULE', 'article_start'), [Token('INDENT', '<<INDENT>>'), Token('INDENT', '<<INDENT>>'), Token('INDENT', '<<INDENT>>'), Token('SPAN_M', '<<SPAN_M>>'), Token('NAT', '7'), Token('RAW_UPPER_TEXT', 'CLAIMS ')])])\n",
      "123932 Tree(Token('RULE', '_heading_start'), [Tree(Token('RULE', 'section_start'), [Token('INDENT', '<<INDENT>>'), Token('SPAN_M_B', '<<SPAN_M_B>>'), Tree(Token('RULE', 'section_number'), [Token('NAT', '3'), Token('NAT', '5'), Token('NAT', '208')]), Token('RAW_TEXT', '  Repealed By Laws 2005, ch. 161, ยง 3. ')])])\n",
      "181919 Tree(Token('RULE', '_heading_start'), [Tree(Token('RULE', 'section_start'), [Token('INDENT', '<<INDENT>>'), Token('SPAN_M_B', '<<SPAN_M_B>>'), Tree(Token('RULE', 'section_number'), [Token('NAT', '3'), Token('NAT', '8'), Token('NAT', '401')]), Token('RAW_TEXT', '  Registration of guardianship orders. ')])])\n",
      "298742 Tree(Token('RULE', '_heading_start'), [Tree(Token('RULE', 'section_start'), [Token('INDENT', '<<INDENT>>'), Token('SPAN_M_B', '<<SPAN_M_B>>'), Tree(Token('RULE', 'section_number'), [Token('NAT', '3'), Token('NAT', '9'), Token('NAT', '402')]), Token('RAW_TEXT', '  Relation to electronic signatures in global and '), Token('LINE', '<<LINE>>'), Token('SPAN_M_B', '<<SPAN_M_B>>'), Token('RAW_TEXT', 'national commerce act. ')])])\n"
     ]
    }
   ],
   "source": [
    "for idx, parse in idx_parses[::177]:\n",
    "    print(idx, parse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
